<div align="center">
  <br />
    <a href="https://toxic-comment-check.streamlit.app/" target="_blank">
      <img src="https://github.com/user-attachments/assets/91651103-74d5-4f5e-b345-7ca3d2d8ef96" alt="Toxic Comment Check Banner">
    </a>
  <br />

  <div>
    <img src="https://img.shields.io/badge/-Python-black?style=for-the-badge&logoColor=white&logo=python&color=3776AB" alt="python" />
    <img src="https://img.shields.io/badge/-Streamlit-black?style=for-the-badge&logoColor=white&logo=streamlit&color=FF4B4B" alt="streamlit" />
    <img src="https://img.shields.io/badge/-Hugging%20Face-black?style=for-the-badge&logoColor=white&logo=huggingface&color=FFD21E" alt="hugging face" />
    <img src="https://img.shields.io/badge/-PyTorch-black?style=for-the-badge&logoColor=white&logo=pytorch&color=EE4C2C" alt="pytorch" />
  </div>

  <h3 align="center">Toxic Comment Check</h3>

   <div align="center">
     A BERT-based machine learning application that classifies text comments as toxic or non-toxic with real-time analysis and confidence scoring.
    </div>
</div>
<br/>

**Dataset** üóÉÔ∏è
- [Jigsaw Toxic Comment Classification Challenge](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/overview)

## Setup & Installation

**Prerequisites**

Ensure you have the following installed:

- [Git](https://git-scm.com/)
- [Python 3.10+](https://www.python.org/downloads/)
- [pip](https://pip.pypa.io/en/stable/installation/)

**Installation**

1. Clone the repository:
```bash
git clone https://github.com/thebugged/toxic-comment-check.git
```

2. Change into the project directory:
```bash
cd toxic-comment-check
```

3. Install the required dependencies:
```bash
pip install -r requirements.txt
```

**Running the Application**

1. Start the Streamlit server:
```bash
streamlit run main.py
```

2. Open your browser and navigate to `http://localhost:8501`

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://toxic-comment-check.streamlit.app/)

